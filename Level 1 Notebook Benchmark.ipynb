{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "626a022d-5469-4e2c-aba7-c6b00be60b54",
   "metadata": {},
   "source": [
    "# Level 1: Rice Crop Discovery Tool Benchmark Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a03723e-78ae-4150-ba22-e2e485b95cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac\n",
    "import pystac_client\n",
    "import odc\n",
    "from pystac_client import Client\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "from odc.stac import stac_load\n",
    "import xarray as xr\n",
    "import planetary_computer as pc\n",
    "import yaml\n",
    "\n",
    "with open(\"api_key.yml\", 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "# Pass your API key here\n",
    "pc.settings.set_subscription_key(cfg['planetary_computer']['key'])\n",
    "# Others\n",
    "import requests\n",
    "import rich.table\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c268cf6",
   "metadata": {},
   "source": [
    "## Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80dbf04",
   "metadata": {},
   "source": [
    "Before building the model, we need to load in the rice crop presence data. We have curated for you data from a certain region in Vietnam for the year 2020. The data consists of  geo locations (Latitude and Longitude) with a tag specifying if the crop present in each geo location is rice or not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1da678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude and Longitude Class of Land\n",
       "0   (10.323727047081501, 105.2516346045924)          Rice\n",
       "1  (10.322364360592521, 105.27843410554115)          Rice\n",
       "2  (10.321455902933202, 105.25254306225168)          Rice\n",
       "3  (10.324181275911162, 105.25118037576274)          Rice\n",
       "4  (10.324635504740822, 105.27389181724476)          Rice"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_presence_data = pd.read_csv(\"./Data/Crop_Location_Data_20221201.csv\")\n",
    "crop_presence_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6812c-7137-4873-b4ed-2dcdd470209b",
   "metadata": {},
   "source": [
    "## Predictor Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487a9dc-1308-4c05-a69a-ccfe60bc9100",
   "metadata": {},
   "source": [
    "<p align =\"justify\">Now that we have our crop location data, it is time to gather the predictor variables from the Sentinel-1 dataset. For a more in-depth look regarding the Sentinel-1 dataset and how to query it, see the Sentinel-1 <a href=\"https://challenge.ey.com/api/v1/storage/admin-files/6403146221623637-63ca8d537b1fe300146c79d0-Sentinel%201%20Phenology.ipynb/\"> supplementary \n",
    "notebook</a>.\n",
    "    \n",
    "\n",
    "<p align = \"justify\">Sentinel-1 radar data penetrates through the clouds, thus helping us to get the band values with minimal atmospheric attenuation. Band values such as VV and VH help us in distinguishing between the rice and non rice crops. Hence we are choosing VV and VH as predictor variables for this experiment. \n",
    "        \n",
    "<ul>\n",
    "<li>VV - gamma naught values of signal transmitted with vertical polarization and received with vertical polarization with radiometric terrain correction applied.\n",
    "\n",
    "<li>VH - gamma naught values of signal transmitted with vertical polarization and received with horizontal polarization with radiometric terrain correction applied.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04011667-99ae-4820-a635-d8d50f716fe3",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(195, 52, 235)\"><strong>Tip 1</strong></h4>\n",
    "<p align=\"justify\">Participants might explore other combinations of bands from the Sentinel-1 data. For example, you can use mathematical combinations of bands to generate various <a href=\"https://challenge.ey.com/api/v1/storage/admin-files/3868217534768359-63ca8dc8aea56e00146e3489-Comprehensive%20Guide%20-%20Satellite%20Data.docx\">vegetation indices </a> which can then be used as features in your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85257f-4a48-49e8-8036-10e9a6b69894",
   "metadata": {},
   "source": [
    "### Accessing the Sentinel-1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399737c-46bb-44b7-bda8-4253c827e66d",
   "metadata": {},
   "source": [
    "<p align = \"Justify\">To get the Sentinel-1 data, we write a function called <i><b>get_sentinel_data.</b></i> This function will fetch VV and VH band values for a particular location over the specified time window. In this example, we have extracted VV and VH values for a day (21st March 2020). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f85d6d-6c72-438b-81f8-8aafb1265b0a",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(195, 52, 235)\"><strong>Tip 2</strong></h4>\n",
    "<p align=\"justify\"> Extract VV and VH band values for an entire year. Different land classes (e.g., agriculture, water, urban) will have different annual variability. This variability will be better than a single date for accurately identifying land classes. Please find below a demonstration of extracting data for a day (21st March 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e339a34-cfa7-4899-9165-63ca7c01bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinel_data(latlong,time_slice= \"2020-01-01/2020-01-31\",assets=['vv','vh']):\n",
    "    '''\n",
    "    Returns VV and VH values for a given latitude and longitude \n",
    "    Attributes:\n",
    "    latlong - A tuple with 2 elements - latitude and longitude\n",
    "    time_slice - Timeframe for which the VV and VH values have to be extracted\n",
    "    assets - A list of bands to be extracted\n",
    "    '''\n",
    "\n",
    "    latlong=[float(i) for i in latlong.replace('(','').replace(')','').replace(' ','').split(',')]\n",
    "    bbox_of_interest = (float(latlong[1]) , float(latlong[0]), float(latlong[1]) , float(latlong[0]))\n",
    "    time_of_interest = time_slice\n",
    "    catalog = pystac_client.Client.open(\n",
    "            \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    )\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"], bbox=bbox_of_interest, datetime=time_of_interest\n",
    "    )\n",
    "    items = list(search.get_all_items())\n",
    "    data = stac_load(items, patch_url=pc.sign,bands=[\"vv\", \"vh\"], lat=(latlong[0], latlong[0]), lon=(latlong[1], latlong[1])).to_dataframe().reset_index()\n",
    "    data['lat_actual'],data['lon_actual'] = latlong\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab9734-6cdf-466f-87c3-8067b05b90ba",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(195, 52, 235)\"><strong>Tip 3 </strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb9b25-0c41-4f55-aa33-082adeb34dbd",
   "metadata": {},
   "source": [
    "Explore the approach of building a bounding box (e.g., 5x5 pixels) around the given latitude and longitude positions and then extract the aggregated band values (e.g., average, median) to get normalized band values to build the model. Radar data has inherent variability at the pixel level due to variable scattering response from the target. This effect is called “speckle” and it is common to filter the data to smooth these variations. Try using a 3x3, 5x5 or 7x7 window around the specific latitude and longitude point to get improved results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c51cd6e-41e2-4df4-ae07-349be861f0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:00<00:00, 36604.30it/s]\n"
     ]
    }
   ],
   "source": [
    "## Function call to extract VV,VH Values\n",
    "fetch_data = True # Set to False if you have already extracted the data\n",
    "if fetch_data:\n",
    "    time_slice = \"2020-01-01/2020-12-31\"\n",
    "    vh_vv=[]\n",
    "    pool = mp.Pool(mp.cpu_count()-10)\n",
    "    inputs = zip(crop_presence_data['Latitude and Longitude'].values, [time_slice]*len(crop_presence_data))\n",
    "    vh_vv_df = pool.starmap(get_sentinel_data, tqdm(inputs,total=len(crop_presence_data)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    df = pd.concat(vh_vv_df)\n",
    "    df.to_csv('./Data/sentinel_data.csv',index=False)\n",
    "else:\n",
    "    df = pd.read_csv('./Data/sentinel_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c876b6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>time</th>\n",
       "      <th>spatial_ref</th>\n",
       "      <th>vv</th>\n",
       "      <th>vh</th>\n",
       "      <th>lat_actual</th>\n",
       "      <th>lon_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1141215.0</td>\n",
       "      <td>527555.0</td>\n",
       "      <td>2020-01-02 22:45:22.476685</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.147335</td>\n",
       "      <td>0.027236</td>\n",
       "      <td>10.323727</td>\n",
       "      <td>105.251635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1141215.0</td>\n",
       "      <td>527555.0</td>\n",
       "      <td>2020-01-09 11:11:41.420743</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>10.323727</td>\n",
       "      <td>105.251635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1141215.0</td>\n",
       "      <td>527555.0</td>\n",
       "      <td>2020-01-14 22:45:21.932565</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>10.323727</td>\n",
       "      <td>105.251635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1141215.0</td>\n",
       "      <td>527555.0</td>\n",
       "      <td>2020-01-20 22:45:54.277524</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.129160</td>\n",
       "      <td>0.025950</td>\n",
       "      <td>10.323727</td>\n",
       "      <td>105.251635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1141215.0</td>\n",
       "      <td>527555.0</td>\n",
       "      <td>2020-01-21 11:11:40.981936</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.118973</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>10.323727</td>\n",
       "      <td>105.251635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1106825.0</td>\n",
       "      <td>573825.0</td>\n",
       "      <td>2020-12-09 22:46:02.163664</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.341642</td>\n",
       "      <td>0.072926</td>\n",
       "      <td>10.012126</td>\n",
       "      <td>105.673613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1106825.0</td>\n",
       "      <td>573825.0</td>\n",
       "      <td>2020-12-10 11:11:48.884291</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.197114</td>\n",
       "      <td>0.048743</td>\n",
       "      <td>10.012126</td>\n",
       "      <td>105.673613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1106825.0</td>\n",
       "      <td>573825.0</td>\n",
       "      <td>2020-12-15 22:45:29.514434</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.315534</td>\n",
       "      <td>0.056959</td>\n",
       "      <td>10.012126</td>\n",
       "      <td>105.673613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1106825.0</td>\n",
       "      <td>573825.0</td>\n",
       "      <td>2020-12-21 22:46:01.606092</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.195670</td>\n",
       "      <td>0.071512</td>\n",
       "      <td>10.012126</td>\n",
       "      <td>105.673613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1106825.0</td>\n",
       "      <td>573825.0</td>\n",
       "      <td>2020-12-27 22:45:28.898478</td>\n",
       "      <td>32648</td>\n",
       "      <td>0.362040</td>\n",
       "      <td>0.041516</td>\n",
       "      <td>10.012126</td>\n",
       "      <td>105.673613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47415 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y         x                       time  spatial_ref        vv  \\\n",
       "0   1141215.0  527555.0 2020-01-02 22:45:22.476685        32648  0.147335   \n",
       "1   1141215.0  527555.0 2020-01-09 11:11:41.420743        32648  0.100532   \n",
       "2   1141215.0  527555.0 2020-01-14 22:45:21.932565        32648  0.072585   \n",
       "3   1141215.0  527555.0 2020-01-20 22:45:54.277524        32648  0.129160   \n",
       "4   1141215.0  527555.0 2020-01-21 11:11:40.981936        32648  0.118973   \n",
       "..        ...       ...                        ...          ...       ...   \n",
       "74  1106825.0  573825.0 2020-12-09 22:46:02.163664        32648  0.341642   \n",
       "75  1106825.0  573825.0 2020-12-10 11:11:48.884291        32648  0.197114   \n",
       "76  1106825.0  573825.0 2020-12-15 22:45:29.514434        32648  0.315534   \n",
       "77  1106825.0  573825.0 2020-12-21 22:46:01.606092        32648  0.195670   \n",
       "78  1106825.0  573825.0 2020-12-27 22:45:28.898478        32648  0.362040   \n",
       "\n",
       "          vh  lat_actual  lon_actual  \n",
       "0   0.027236   10.323727  105.251635  \n",
       "1   0.035662   10.323727  105.251635  \n",
       "2   0.028481   10.323727  105.251635  \n",
       "3   0.025950   10.323727  105.251635  \n",
       "4   0.039736   10.323727  105.251635  \n",
       "..       ...         ...         ...  \n",
       "74  0.072926   10.012126  105.673613  \n",
       "75  0.048743   10.012126  105.673613  \n",
       "76  0.056959   10.012126  105.673613  \n",
       "77  0.071512   10.012126  105.673613  \n",
       "78  0.041516   10.012126  105.673613  \n",
       "\n",
       "[47415 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2629f3f5-5a51-45d7-9c68-75b969101405",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ca6534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 10:05:34.577875: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 10:05:34.742746: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-26 10:05:34.774246: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-26 10:05:35.295589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-26 10:05:35.295642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-26 10:05:35.295648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display,clear_output\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326eef15",
   "metadata": {},
   "source": [
    "### Expermient 1 : VV Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdba574",
   "metadata": {},
   "source": [
    "##### Data Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd4fbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude and Longitude Class of Land\n",
       "0   (10.323727047081501, 105.2516346045924)          Rice\n",
       "1  (10.322364360592521, 105.27843410554115)          Rice\n",
       "2  (10.321455902933202, 105.25254306225168)          Rice\n",
       "3  (10.324181275911162, 105.25118037576274)          Rice\n",
       "4  (10.324635504740822, 105.27389181724476)          Rice"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136713</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>0.052516</td>\n",
       "      <td>0.113325</td>\n",
       "      <td>0.180918</td>\n",
       "      <td>0.084581</td>\n",
       "      <td>0.236054</td>\n",
       "      <td>0.138249</td>\n",
       "      <td>0.222160</td>\n",
       "      <td>0.082468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131975</td>\n",
       "      <td>0.116991</td>\n",
       "      <td>0.129285</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.016335</td>\n",
       "      <td>0.118973</td>\n",
       "      <td>0.129160</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>0.147335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.073629</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>0.183774</td>\n",
       "      <td>0.112656</td>\n",
       "      <td>0.119053</td>\n",
       "      <td>0.125759</td>\n",
       "      <td>0.184625</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169769</td>\n",
       "      <td>0.093939</td>\n",
       "      <td>0.086115</td>\n",
       "      <td>0.061664</td>\n",
       "      <td>0.042575</td>\n",
       "      <td>0.174255</td>\n",
       "      <td>0.159475</td>\n",
       "      <td>0.112408</td>\n",
       "      <td>0.367571</td>\n",
       "      <td>0.253594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103548</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.078220</td>\n",
       "      <td>0.217244</td>\n",
       "      <td>0.307188</td>\n",
       "      <td>0.277898</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>0.082699</td>\n",
       "      <td>0.146055</td>\n",
       "      <td>0.026883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124293</td>\n",
       "      <td>0.082959</td>\n",
       "      <td>0.143766</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.029017</td>\n",
       "      <td>0.096281</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.049105</td>\n",
       "      <td>0.397772</td>\n",
       "      <td>0.136151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.112445</td>\n",
       "      <td>0.039681</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.074011</td>\n",
       "      <td>0.240549</td>\n",
       "      <td>0.296535</td>\n",
       "      <td>0.072409</td>\n",
       "      <td>0.135074</td>\n",
       "      <td>0.096405</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097248</td>\n",
       "      <td>0.079721</td>\n",
       "      <td>0.189882</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.076895</td>\n",
       "      <td>0.081524</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.099842</td>\n",
       "      <td>0.183957</td>\n",
       "      <td>0.230961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041582</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>0.049128</td>\n",
       "      <td>0.104897</td>\n",
       "      <td>0.099337</td>\n",
       "      <td>0.077988</td>\n",
       "      <td>0.367231</td>\n",
       "      <td>0.664374</td>\n",
       "      <td>0.036919</td>\n",
       "      <td>0.331721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188886</td>\n",
       "      <td>0.175489</td>\n",
       "      <td>0.172606</td>\n",
       "      <td>0.058966</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>0.077754</td>\n",
       "      <td>0.125112</td>\n",
       "      <td>0.175304</td>\n",
       "      <td>0.111650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.136713  0.019095  0.052516  0.113325  0.180918  0.084581  0.236054   \n",
       "1  0.008367  0.073629  0.013057  0.102261  0.183774  0.112656  0.119053   \n",
       "2  0.103548  0.036345  0.078220  0.217244  0.307188  0.277898  0.113407   \n",
       "3  0.112445  0.039681  0.022097  0.074011  0.240549  0.296535  0.072409   \n",
       "4  0.041582  0.012306  0.049128  0.104897  0.099337  0.077988  0.367231   \n",
       "\n",
       "          7         8         9  ...        69        70        71        72  \\\n",
       "0  0.138249  0.222160  0.082468  ...  0.131975  0.116991  0.129285  0.034969   \n",
       "1  0.125759  0.184625  0.052343  ...  0.169769  0.093939  0.086115  0.061664   \n",
       "2  0.082699  0.146055  0.026883  ...  0.124293  0.082959  0.143766  0.017497   \n",
       "3  0.135074  0.096405  0.059797  ...  0.097248  0.079721  0.189882  0.030258   \n",
       "4  0.664374  0.036919  0.331721  ...  0.188886  0.175489  0.172606  0.058966   \n",
       "\n",
       "         73        74        75        76        77        78  \n",
       "0  0.016335  0.118973  0.129160  0.072585  0.100532  0.147335  \n",
       "1  0.042575  0.174255  0.159475  0.112408  0.367571  0.253594  \n",
       "2  0.029017  0.096281  0.042791  0.049105  0.397772  0.136151  \n",
       "3  0.076895  0.081524  0.069514  0.099842  0.183957  0.230961  \n",
       "4  0.065165  0.099678  0.077754  0.125112  0.175304  0.111650  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crop_presence_data = pd.read_csv(\"./Data/Crop_Location_Data_20221201.csv\")\n",
    "display(crop_presence_data.head())\n",
    "aux_data = pd.read_csv(\"./Data/S1DataVVProcessed.csv\",index_col=0)\n",
    "display(aux_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d32733",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([crop_presence_data,aux_data],axis=1)\n",
    "data.drop(['Latitude and Longitude'],axis=1,inplace=True)\n",
    "miss_rate=data.apply(lambda x: 1-x.isna().value_counts()[False]/len(x),axis=0)\n",
    "# drop columns with missing rate > 0.5\n",
    "data.drop(miss_rate[miss_rate>0.1].index,axis=1,inplace=True)\n",
    "data.replace([-32768.000000],np.nan,inplace=True)\n",
    "target_value=data['Class of Land'].apply(lambda x: 1 if x=='Rice' else 0)\n",
    "data.drop(['Class of Land'],axis=1,inplace=True)\n",
    "# fill missing values with mean\n",
    "data.fillna(data.mean(axis=0),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc134ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136713</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>0.052516</td>\n",
       "      <td>0.113325</td>\n",
       "      <td>0.180918</td>\n",
       "      <td>0.084581</td>\n",
       "      <td>0.236054</td>\n",
       "      <td>0.138249</td>\n",
       "      <td>0.222160</td>\n",
       "      <td>0.082468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131975</td>\n",
       "      <td>0.116991</td>\n",
       "      <td>0.129285</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.016335</td>\n",
       "      <td>0.118973</td>\n",
       "      <td>0.129160</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>0.147335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.073629</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>0.183774</td>\n",
       "      <td>0.112656</td>\n",
       "      <td>0.119053</td>\n",
       "      <td>0.125759</td>\n",
       "      <td>0.184625</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169769</td>\n",
       "      <td>0.093939</td>\n",
       "      <td>0.086115</td>\n",
       "      <td>0.061664</td>\n",
       "      <td>0.042575</td>\n",
       "      <td>0.174255</td>\n",
       "      <td>0.159475</td>\n",
       "      <td>0.112408</td>\n",
       "      <td>0.367571</td>\n",
       "      <td>0.253594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103548</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.078220</td>\n",
       "      <td>0.217244</td>\n",
       "      <td>0.307188</td>\n",
       "      <td>0.277898</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>0.082699</td>\n",
       "      <td>0.146055</td>\n",
       "      <td>0.026883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124293</td>\n",
       "      <td>0.082959</td>\n",
       "      <td>0.143766</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.029017</td>\n",
       "      <td>0.096281</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.049105</td>\n",
       "      <td>0.397772</td>\n",
       "      <td>0.136151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.112445</td>\n",
       "      <td>0.039681</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.074011</td>\n",
       "      <td>0.240549</td>\n",
       "      <td>0.296535</td>\n",
       "      <td>0.072409</td>\n",
       "      <td>0.135074</td>\n",
       "      <td>0.096405</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097248</td>\n",
       "      <td>0.079721</td>\n",
       "      <td>0.189882</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.076895</td>\n",
       "      <td>0.081524</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.099842</td>\n",
       "      <td>0.183957</td>\n",
       "      <td>0.230961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041582</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>0.049128</td>\n",
       "      <td>0.104897</td>\n",
       "      <td>0.099337</td>\n",
       "      <td>0.077988</td>\n",
       "      <td>0.367231</td>\n",
       "      <td>0.664374</td>\n",
       "      <td>0.036919</td>\n",
       "      <td>0.331721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188886</td>\n",
       "      <td>0.175489</td>\n",
       "      <td>0.172606</td>\n",
       "      <td>0.058966</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>0.077754</td>\n",
       "      <td>0.125112</td>\n",
       "      <td>0.175304</td>\n",
       "      <td>0.111650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.209653</td>\n",
       "      <td>0.132859</td>\n",
       "      <td>0.340596</td>\n",
       "      <td>0.118031</td>\n",
       "      <td>0.212445</td>\n",
       "      <td>0.514146</td>\n",
       "      <td>0.202694</td>\n",
       "      <td>0.230627</td>\n",
       "      <td>0.553938</td>\n",
       "      <td>0.127156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255218</td>\n",
       "      <td>0.209444</td>\n",
       "      <td>0.477707</td>\n",
       "      <td>0.249642</td>\n",
       "      <td>0.190894</td>\n",
       "      <td>0.221262</td>\n",
       "      <td>0.152839</td>\n",
       "      <td>0.472225</td>\n",
       "      <td>0.193266</td>\n",
       "      <td>0.349118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.345177</td>\n",
       "      <td>0.333710</td>\n",
       "      <td>0.156724</td>\n",
       "      <td>0.239881</td>\n",
       "      <td>0.354379</td>\n",
       "      <td>0.309487</td>\n",
       "      <td>0.100985</td>\n",
       "      <td>0.327562</td>\n",
       "      <td>0.577501</td>\n",
       "      <td>0.406944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459707</td>\n",
       "      <td>0.165649</td>\n",
       "      <td>0.225630</td>\n",
       "      <td>0.252992</td>\n",
       "      <td>0.276695</td>\n",
       "      <td>0.183418</td>\n",
       "      <td>0.426954</td>\n",
       "      <td>0.477477</td>\n",
       "      <td>0.174691</td>\n",
       "      <td>0.168521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.422360</td>\n",
       "      <td>0.267347</td>\n",
       "      <td>0.946567</td>\n",
       "      <td>0.164242</td>\n",
       "      <td>0.374150</td>\n",
       "      <td>0.391451</td>\n",
       "      <td>0.318233</td>\n",
       "      <td>0.247475</td>\n",
       "      <td>0.396374</td>\n",
       "      <td>0.302028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376712</td>\n",
       "      <td>0.182609</td>\n",
       "      <td>0.460066</td>\n",
       "      <td>0.263639</td>\n",
       "      <td>0.376831</td>\n",
       "      <td>0.403079</td>\n",
       "      <td>0.604752</td>\n",
       "      <td>0.491092</td>\n",
       "      <td>0.293945</td>\n",
       "      <td>0.561207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.088473</td>\n",
       "      <td>0.200898</td>\n",
       "      <td>0.239337</td>\n",
       "      <td>0.302809</td>\n",
       "      <td>0.287695</td>\n",
       "      <td>0.115140</td>\n",
       "      <td>0.175324</td>\n",
       "      <td>0.227792</td>\n",
       "      <td>0.389689</td>\n",
       "      <td>0.454797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258151</td>\n",
       "      <td>0.209155</td>\n",
       "      <td>0.120049</td>\n",
       "      <td>0.310898</td>\n",
       "      <td>0.306119</td>\n",
       "      <td>0.450686</td>\n",
       "      <td>0.223350</td>\n",
       "      <td>0.145055</td>\n",
       "      <td>0.340870</td>\n",
       "      <td>0.186654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.362040</td>\n",
       "      <td>0.195670</td>\n",
       "      <td>0.315534</td>\n",
       "      <td>0.197114</td>\n",
       "      <td>0.341642</td>\n",
       "      <td>0.317655</td>\n",
       "      <td>0.181954</td>\n",
       "      <td>0.359402</td>\n",
       "      <td>0.612758</td>\n",
       "      <td>0.220497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191205</td>\n",
       "      <td>0.200468</td>\n",
       "      <td>0.384395</td>\n",
       "      <td>0.170185</td>\n",
       "      <td>0.454650</td>\n",
       "      <td>0.235978</td>\n",
       "      <td>0.168147</td>\n",
       "      <td>0.258776</td>\n",
       "      <td>0.317216</td>\n",
       "      <td>0.217147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.136713  0.019095  0.052516  0.113325  0.180918  0.084581  0.236054   \n",
       "1    0.008367  0.073629  0.013057  0.102261  0.183774  0.112656  0.119053   \n",
       "2    0.103548  0.036345  0.078220  0.217244  0.307188  0.277898  0.113407   \n",
       "3    0.112445  0.039681  0.022097  0.074011  0.240549  0.296535  0.072409   \n",
       "4    0.041582  0.012306  0.049128  0.104897  0.099337  0.077988  0.367231   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "595  0.209653  0.132859  0.340596  0.118031  0.212445  0.514146  0.202694   \n",
       "596  0.345177  0.333710  0.156724  0.239881  0.354379  0.309487  0.100985   \n",
       "597  0.422360  0.267347  0.946567  0.164242  0.374150  0.391451  0.318233   \n",
       "598  0.088473  0.200898  0.239337  0.302809  0.287695  0.115140  0.175324   \n",
       "599  0.362040  0.195670  0.315534  0.197114  0.341642  0.317655  0.181954   \n",
       "\n",
       "            7         8         9  ...        69        70        71  \\\n",
       "0    0.138249  0.222160  0.082468  ...  0.131975  0.116991  0.129285   \n",
       "1    0.125759  0.184625  0.052343  ...  0.169769  0.093939  0.086115   \n",
       "2    0.082699  0.146055  0.026883  ...  0.124293  0.082959  0.143766   \n",
       "3    0.135074  0.096405  0.059797  ...  0.097248  0.079721  0.189882   \n",
       "4    0.664374  0.036919  0.331721  ...  0.188886  0.175489  0.172606   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "595  0.230627  0.553938  0.127156  ...  0.255218  0.209444  0.477707   \n",
       "596  0.327562  0.577501  0.406944  ...  0.459707  0.165649  0.225630   \n",
       "597  0.247475  0.396374  0.302028  ...  0.376712  0.182609  0.460066   \n",
       "598  0.227792  0.389689  0.454797  ...  0.258151  0.209155  0.120049   \n",
       "599  0.359402  0.612758  0.220497  ...  0.191205  0.200468  0.384395   \n",
       "\n",
       "           72        73        74        75        76        77        78  \n",
       "0    0.034969  0.016335  0.118973  0.129160  0.072585  0.100532  0.147335  \n",
       "1    0.061664  0.042575  0.174255  0.159475  0.112408  0.367571  0.253594  \n",
       "2    0.017497  0.029017  0.096281  0.042791  0.049105  0.397772  0.136151  \n",
       "3    0.030258  0.076895  0.081524  0.069514  0.099842  0.183957  0.230961  \n",
       "4    0.058966  0.065165  0.099678  0.077754  0.125112  0.175304  0.111650  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "595  0.249642  0.190894  0.221262  0.152839  0.472225  0.193266  0.349118  \n",
       "596  0.252992  0.276695  0.183418  0.426954  0.477477  0.174691  0.168521  \n",
       "597  0.263639  0.376831  0.403079  0.604752  0.491092  0.293945  0.561207  \n",
       "598  0.310898  0.306119  0.450686  0.223350  0.145055  0.340870  0.186654  \n",
       "599  0.170185  0.454650  0.235978  0.168147  0.258776  0.317216  0.217147  \n",
       "\n",
       "[600 rows x 79 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9457eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Test Data\n",
    "os.makedirs('./Submission_Data',exist_ok=True)\n",
    "submit_fp ='./Submission_Data/'\n",
    "submission_df = pd.read_csv('./Data/challenge_1_submission_template_correct_columns_fixed.csv')\n",
    "\n",
    "replace_data,save_test_file = False,\"./Data/TestS1DataVVProcessed.csv\"\n",
    "if not os.path.exists(save_test_file) or replace_data:\n",
    "    # extract data\n",
    "    pass\n",
    "test_data = pd.read_csv(save_test_file)\n",
    "test_data=test_data.loc[:,data.columns]\n",
    "test_data.replace([-32768.000000],np.nan,inplace=True)\n",
    "test_data.fillna(data.mean(axis=0),inplace=True)\n",
    "X_test = test_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517535a",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123b56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow check cuda availability\n",
    "devices_=tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_logical_device_configuration(device=devices_[0],logical_devices=[tf.config.LogicalDeviceConfiguration(memory_limit=1024*22)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "194e3a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 09:51:27.124588: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 09:51:28.248130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21267 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2023-03-26 09:51:28.249242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22292 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:86:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Sequenial Keras model 2 LSTM Layer with 10 neurons each and 1 Dense layer with 1 neuron\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=(79,1)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(50,return_sequences=True)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(50)))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "626628b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "EPOCHS=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d44fb15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test using sklearn random split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, target_value, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert the data into numpy array and reshape the data to fit the model\n",
    "X_train = X_train.to_numpy().reshape(-1,79,1)\n",
    "X_val = X_val.to_numpy().reshape(-1,79,1)\n",
    "y_train = y_train.to_numpy().reshape(-1,1)\n",
    "y_val = y_val.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "905d2140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 09:52:01.250982: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2023-03-26 09:52:02.383308: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 6s 108ms/step - loss: 0.6681 - accuracy: 0.4000 - val_loss: 0.6507 - val_accuracy: 0.3583\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5159 - accuracy: 0.7188 - val_loss: 0.4430 - val_accuracy: 0.8083\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4262 - accuracy: 0.7979 - val_loss: 0.7269 - val_accuracy: 0.7083\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5065 - accuracy: 0.7812 - val_loss: 0.2386 - val_accuracy: 0.9333\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2065 - accuracy: 0.9208 - val_loss: 1.1221 - val_accuracy: 0.8417\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6434 - accuracy: 0.8667 - val_loss: 0.3877 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.3054 - accuracy: 0.8667 - val_loss: 0.2207 - val_accuracy: 0.9417\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2126 - accuracy: 0.9375 - val_loss: 0.4808 - val_accuracy: 0.7917\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4929 - accuracy: 0.7875 - val_loss: 0.4714 - val_accuracy: 0.7917\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.3631 - accuracy: 0.8354 - val_loss: 0.2347 - val_accuracy: 0.9583\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2467 - accuracy: 0.9333 - val_loss: 0.2099 - val_accuracy: 0.9250\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1869 - accuracy: 0.9438 - val_loss: 0.3519 - val_accuracy: 0.8750\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3127 - accuracy: 0.8792 - val_loss: 0.2236 - val_accuracy: 0.9417\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2432 - accuracy: 0.9208 - val_loss: 0.2131 - val_accuracy: 0.9250\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1646 - accuracy: 0.9500 - val_loss: 0.2068 - val_accuracy: 0.9417\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2170 - accuracy: 0.9229 - val_loss: 0.1733 - val_accuracy: 0.9417\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.1740 - accuracy: 0.9479 - val_loss: 0.1597 - val_accuracy: 0.9667\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.1915 - accuracy: 0.9333 - val_loss: 0.1294 - val_accuracy: 0.9833\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1609 - accuracy: 0.9479 - val_loss: 0.1794 - val_accuracy: 0.9333\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1503 - accuracy: 0.9500 - val_loss: 0.1947 - val_accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1484 - accuracy: 0.9438 - val_loss: 0.1636 - val_accuracy: 0.9500\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1527 - accuracy: 0.9375 - val_loss: 0.1402 - val_accuracy: 0.9750\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1458 - accuracy: 0.9500 - val_loss: 0.1257 - val_accuracy: 0.9667\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1211 - accuracy: 0.9563 - val_loss: 0.1209 - val_accuracy: 0.9583\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1258 - accuracy: 0.9583 - val_loss: 0.2425 - val_accuracy: 0.8917\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1643 - accuracy: 0.9417 - val_loss: 0.1283 - val_accuracy: 0.9583\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1468 - accuracy: 0.9563 - val_loss: 0.1165 - val_accuracy: 0.9833\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1615 - accuracy: 0.9396 - val_loss: 0.1207 - val_accuracy: 0.9750\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1441 - accuracy: 0.9458 - val_loss: 0.1242 - val_accuracy: 0.9667\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1460 - accuracy: 0.9396 - val_loss: 0.1210 - val_accuracy: 0.9750\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1316 - accuracy: 0.9479 - val_loss: 0.1344 - val_accuracy: 0.9583\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1171 - accuracy: 0.9458 - val_loss: 0.1373 - val_accuracy: 0.9500\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1451 - accuracy: 0.9458 - val_loss: 0.3170 - val_accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1607 - accuracy: 0.9354 - val_loss: 0.1559 - val_accuracy: 0.9500\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1248 - accuracy: 0.9542 - val_loss: 0.1072 - val_accuracy: 0.9833\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1041 - accuracy: 0.9604 - val_loss: 0.1350 - val_accuracy: 0.9583\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1084 - accuracy: 0.9646 - val_loss: 0.1276 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1085 - accuracy: 0.9563 - val_loss: 0.1294 - val_accuracy: 0.9583\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1142 - accuracy: 0.9604 - val_loss: 0.1291 - val_accuracy: 0.9583\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1046 - accuracy: 0.9667 - val_loss: 0.1150 - val_accuracy: 0.9667\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0890 - accuracy: 0.9688 - val_loss: 0.1174 - val_accuracy: 0.9667\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0883 - accuracy: 0.9625 - val_loss: 0.1056 - val_accuracy: 0.9667\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0787 - accuracy: 0.9750 - val_loss: 0.1177 - val_accuracy: 0.9583\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0665 - accuracy: 0.9771 - val_loss: 0.0957 - val_accuracy: 0.9833\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0743 - accuracy: 0.9771 - val_loss: 0.1253 - val_accuracy: 0.9583\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1086 - accuracy: 0.9563 - val_loss: 0.1503 - val_accuracy: 0.9417\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1131 - accuracy: 0.9563 - val_loss: 0.1028 - val_accuracy: 0.9833\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0935 - accuracy: 0.9542 - val_loss: 0.1061 - val_accuracy: 0.9583\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0848 - accuracy: 0.9729 - val_loss: 0.0943 - val_accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0893 - accuracy: 0.9729 - val_loss: 0.1182 - val_accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0906 - accuracy: 0.9729 - val_loss: 0.1084 - val_accuracy: 0.9750\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1026 - accuracy: 0.9667 - val_loss: 0.1230 - val_accuracy: 0.9750\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0698 - accuracy: 0.9812 - val_loss: 0.1418 - val_accuracy: 0.9667\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0647 - accuracy: 0.9833 - val_loss: 0.1233 - val_accuracy: 0.9667\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0602 - accuracy: 0.9854 - val_loss: 0.1428 - val_accuracy: 0.9583\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0638 - accuracy: 0.9792 - val_loss: 0.1105 - val_accuracy: 0.9500\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0537 - accuracy: 0.9854 - val_loss: 0.1318 - val_accuracy: 0.9583\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0502 - accuracy: 0.9875 - val_loss: 0.0690 - val_accuracy: 0.9750\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0467 - accuracy: 0.9896 - val_loss: 0.1264 - val_accuracy: 0.9750\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 0.1197 - val_accuracy: 0.9667\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0648 - accuracy: 0.9750 - val_loss: 0.1307 - val_accuracy: 0.9583\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0924 - accuracy: 0.9646 - val_loss: 0.1253 - val_accuracy: 0.9667\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0552 - accuracy: 0.9854 - val_loss: 0.0850 - val_accuracy: 0.9750\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0509 - accuracy: 0.9854 - val_loss: 0.1062 - val_accuracy: 0.9583\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.1280 - val_accuracy: 0.9583\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0441 - accuracy: 0.9854 - val_loss: 0.1013 - val_accuracy: 0.9667\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0385 - accuracy: 0.9896 - val_loss: 0.0703 - val_accuracy: 0.9833\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0331 - accuracy: 0.9875 - val_loss: 0.0897 - val_accuracy: 0.9667\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0305 - accuracy: 0.9937 - val_loss: 0.0909 - val_accuracy: 0.9750\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0892 - val_accuracy: 0.9750\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0312 - accuracy: 0.9854 - val_loss: 0.0975 - val_accuracy: 0.9667\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.0892 - val_accuracy: 0.9750\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0258 - accuracy: 0.9896 - val_loss: 0.0862 - val_accuracy: 0.9750\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0828 - val_accuracy: 0.9750\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0212 - accuracy: 0.9917 - val_loss: 0.0793 - val_accuracy: 0.9833\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0272 - accuracy: 0.9875 - val_loss: 0.0864 - val_accuracy: 0.9750\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.0890 - val_accuracy: 0.9750\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0691 - accuracy: 0.9729 - val_loss: 0.0797 - val_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0989 - accuracy: 0.9604 - val_loss: 0.0442 - val_accuracy: 0.9917\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0859 - accuracy: 0.9583 - val_loss: 0.0817 - val_accuracy: 0.9750\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1030 - accuracy: 0.9667 - val_loss: 0.0429 - val_accuracy: 0.9833\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0536 - accuracy: 0.9812 - val_loss: 0.0384 - val_accuracy: 0.9917\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0693 - accuracy: 0.9812 - val_loss: 0.0518 - val_accuracy: 0.9833\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0856 - accuracy: 0.9688 - val_loss: 0.0758 - val_accuracy: 0.9583\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0505 - accuracy: 0.9854 - val_loss: 0.0492 - val_accuracy: 0.9833\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 0.0296 - val_accuracy: 0.9917\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 0.0214 - val_accuracy: 0.9917\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0365 - accuracy: 0.9875 - val_loss: 0.0301 - val_accuracy: 0.9917\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0278 - accuracy: 0.9896 - val_loss: 0.0192 - val_accuracy: 0.9917\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0280 - accuracy: 0.9875 - val_loss: 0.0854 - val_accuracy: 0.9667\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0650 - accuracy: 0.9812 - val_loss: 0.0729 - val_accuracy: 0.9833\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0984 - accuracy: 0.9625 - val_loss: 0.0782 - val_accuracy: 0.9667\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1026 - accuracy: 0.9625 - val_loss: 0.0612 - val_accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0780 - accuracy: 0.9771 - val_loss: 0.0786 - val_accuracy: 0.9667\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0556 - accuracy: 0.9875 - val_loss: 0.0682 - val_accuracy: 0.9750\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3032 - accuracy: 0.8833 - val_loss: 0.3353 - val_accuracy: 0.8083\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3008 - accuracy: 0.8687 - val_loss: 0.5442 - val_accuracy: 0.7250\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1991 - accuracy: 0.9146 - val_loss: 0.1259 - val_accuracy: 0.9583\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0841 - accuracy: 0.9771 - val_loss: 0.1051 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fa50b06bfd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model with model checkpoint best validation loss and early stopping with patience 5\n",
    "checkpoint_filepath = './checkpoint/'\n",
    "os.makedirs(os.path.dirname(checkpoint_filepath), exist_ok=True)\n",
    "checkpoint_filepath = './checkpoint/checkpoint2'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, validation_data=(X_val, y_val), callbacks=[model_checkpoint_callback,early_stopping])\n",
    "model.fit(np.concatenate([X_train,X_val],axis=0), np.concatenate([y_train,y_val],axis=0), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,validation_split=0.2, callbacks=[model_checkpoint_callback])\n",
    "model.load_weights(checkpoint_filepath)\n",
    "# model.evaluate(x=X_val,y=y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b65ca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01426310371607542, 1.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_val,y=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa601ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "submission_df['target']=model.predict(X_test).argmax(axis=1)\n",
    "submission_df['target']=submission_df['target'].apply(lambda x: 'Rice' if x==1 else 'Non Rice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1ad32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df=pd.read_csv('./Data/Best_submission.csv').rename({'target':'best_target'},axis=1).merge(submission_df,on=['id'],how='left')\n",
    "compare_df['is_equal']=compare_df.apply(lambda x: 1 if x['best_target']==x['target'] else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85ae994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(os.path.join(submit_fp,\"Out2.csv\"),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c5195",
   "metadata": {},
   "source": [
    "### Experiment 2: VH + VV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9cbc3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data Set\n",
    "\n",
    "def data_preprocess(df_input):\n",
    "    df = df_input.copy()\n",
    "    miss_rate=df.apply(lambda x: 1-x.isna().value_counts()[False]/len(x),axis=0)\n",
    "    df.drop(miss_rate[miss_rate>0.1].index,axis=1,inplace=True)\n",
    "    df.replace([-32768.000000],np.nan,inplace=True)\n",
    "    df.fillna(df.mean(axis=0),inplace=True)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67012397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude and Longitude Class of Land\n",
       "0   (10.323727047081501, 105.2516346045924)          Rice\n",
       "1  (10.322364360592521, 105.27843410554115)          Rice\n",
       "2  (10.321455902933202, 105.25254306225168)          Rice\n",
       "3  (10.324181275911162, 105.25118037576274)          Rice\n",
       "4  (10.324635504740822, 105.27389181724476)          Rice"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004257</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.009961</td>\n",
       "      <td>0.018752</td>\n",
       "      <td>0.056223</td>\n",
       "      <td>0.046123</td>\n",
       "      <td>0.028594</td>\n",
       "      <td>0.063402</td>\n",
       "      <td>0.063434</td>\n",
       "      <td>0.039090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022627</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>0.056788</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>0.025950</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>0.027236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.017472</td>\n",
       "      <td>0.023758</td>\n",
       "      <td>0.034844</td>\n",
       "      <td>0.136051</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>0.046194</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066685</td>\n",
       "      <td>0.083743</td>\n",
       "      <td>0.111567</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>0.019166</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.043713</td>\n",
       "      <td>0.020591</td>\n",
       "      <td>0.039421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012065</td>\n",
       "      <td>0.014525</td>\n",
       "      <td>0.069244</td>\n",
       "      <td>0.041848</td>\n",
       "      <td>0.033582</td>\n",
       "      <td>0.074039</td>\n",
       "      <td>0.104345</td>\n",
       "      <td>0.030171</td>\n",
       "      <td>0.042813</td>\n",
       "      <td>0.028010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032459</td>\n",
       "      <td>0.018907</td>\n",
       "      <td>0.083230</td>\n",
       "      <td>0.034847</td>\n",
       "      <td>0.010436</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>0.017816</td>\n",
       "      <td>0.012061</td>\n",
       "      <td>0.020985</td>\n",
       "      <td>0.033677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>0.074877</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.019093</td>\n",
       "      <td>0.058226</td>\n",
       "      <td>0.042667</td>\n",
       "      <td>0.029065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043986</td>\n",
       "      <td>0.044804</td>\n",
       "      <td>0.086023</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.019991</td>\n",
       "      <td>0.005546</td>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.013266</td>\n",
       "      <td>0.042812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.014432</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.041154</td>\n",
       "      <td>0.062224</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>0.183996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042198</td>\n",
       "      <td>0.038811</td>\n",
       "      <td>0.036053</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.019257</td>\n",
       "      <td>0.035105</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>0.038898</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.029217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.004257  0.006852  0.009961  0.018752  0.056223  0.046123  0.028594   \n",
       "1  0.005324  0.009781  0.003606  0.017472  0.023758  0.034844  0.136051   \n",
       "2  0.012065  0.014525  0.069244  0.041848  0.033582  0.074039  0.104345   \n",
       "3  0.004077  0.006702  0.007304  0.012286  0.074877  0.099660  0.019093   \n",
       "4  0.001757  0.003051  0.002617  0.014432  0.009542  0.006758  0.041154   \n",
       "\n",
       "          7         8         9  ...        69        70        71        72  \\\n",
       "0  0.063402  0.063434  0.039090  ...  0.022627  0.042624  0.056788  0.009047   \n",
       "1  0.028345  0.046194  0.039960  ...  0.066685  0.083743  0.111567  0.031366   \n",
       "2  0.030171  0.042813  0.028010  ...  0.032459  0.018907  0.083230  0.034847   \n",
       "3  0.058226  0.042667  0.029065  ...  0.043986  0.044804  0.086023  0.017242   \n",
       "4  0.062224  0.010816  0.183996  ...  0.042198  0.038811  0.036053  0.010171   \n",
       "\n",
       "         73        74        75        76        77        78  \n",
       "0  0.010800  0.039736  0.025950  0.028481  0.035662  0.027236  \n",
       "1  0.052280  0.019166  0.018328  0.043713  0.020591  0.039421  \n",
       "2  0.010436  0.020277  0.017816  0.012061  0.020985  0.033677  \n",
       "3  0.019991  0.005546  0.017439  0.015310  0.013266  0.042812  \n",
       "4  0.019257  0.035105  0.022845  0.038898  0.009312  0.029217  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136713</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>0.052516</td>\n",
       "      <td>0.113325</td>\n",
       "      <td>0.180918</td>\n",
       "      <td>0.084581</td>\n",
       "      <td>0.236054</td>\n",
       "      <td>0.138249</td>\n",
       "      <td>0.222160</td>\n",
       "      <td>0.082468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131975</td>\n",
       "      <td>0.116991</td>\n",
       "      <td>0.129285</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.016335</td>\n",
       "      <td>0.118973</td>\n",
       "      <td>0.129160</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>0.100532</td>\n",
       "      <td>0.147335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.073629</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>0.183774</td>\n",
       "      <td>0.112656</td>\n",
       "      <td>0.119053</td>\n",
       "      <td>0.125759</td>\n",
       "      <td>0.184625</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169769</td>\n",
       "      <td>0.093939</td>\n",
       "      <td>0.086115</td>\n",
       "      <td>0.061664</td>\n",
       "      <td>0.042575</td>\n",
       "      <td>0.174255</td>\n",
       "      <td>0.159475</td>\n",
       "      <td>0.112408</td>\n",
       "      <td>0.367571</td>\n",
       "      <td>0.253594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103548</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.078220</td>\n",
       "      <td>0.217244</td>\n",
       "      <td>0.307188</td>\n",
       "      <td>0.277898</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>0.082699</td>\n",
       "      <td>0.146055</td>\n",
       "      <td>0.026883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124293</td>\n",
       "      <td>0.082959</td>\n",
       "      <td>0.143766</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.029017</td>\n",
       "      <td>0.096281</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.049105</td>\n",
       "      <td>0.397772</td>\n",
       "      <td>0.136151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.112445</td>\n",
       "      <td>0.039681</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.074011</td>\n",
       "      <td>0.240549</td>\n",
       "      <td>0.296535</td>\n",
       "      <td>0.072409</td>\n",
       "      <td>0.135074</td>\n",
       "      <td>0.096405</td>\n",
       "      <td>0.059797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097248</td>\n",
       "      <td>0.079721</td>\n",
       "      <td>0.189882</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.076895</td>\n",
       "      <td>0.081524</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.099842</td>\n",
       "      <td>0.183957</td>\n",
       "      <td>0.230961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041582</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>0.049128</td>\n",
       "      <td>0.104897</td>\n",
       "      <td>0.099337</td>\n",
       "      <td>0.077988</td>\n",
       "      <td>0.367231</td>\n",
       "      <td>0.664374</td>\n",
       "      <td>0.036919</td>\n",
       "      <td>0.331721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188886</td>\n",
       "      <td>0.175489</td>\n",
       "      <td>0.172606</td>\n",
       "      <td>0.058966</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>0.077754</td>\n",
       "      <td>0.125112</td>\n",
       "      <td>0.175304</td>\n",
       "      <td>0.111650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.136713  0.019095  0.052516  0.113325  0.180918  0.084581  0.236054   \n",
       "1  0.008367  0.073629  0.013057  0.102261  0.183774  0.112656  0.119053   \n",
       "2  0.103548  0.036345  0.078220  0.217244  0.307188  0.277898  0.113407   \n",
       "3  0.112445  0.039681  0.022097  0.074011  0.240549  0.296535  0.072409   \n",
       "4  0.041582  0.012306  0.049128  0.104897  0.099337  0.077988  0.367231   \n",
       "\n",
       "          7         8         9  ...        69        70        71        72  \\\n",
       "0  0.138249  0.222160  0.082468  ...  0.131975  0.116991  0.129285  0.034969   \n",
       "1  0.125759  0.184625  0.052343  ...  0.169769  0.093939  0.086115  0.061664   \n",
       "2  0.082699  0.146055  0.026883  ...  0.124293  0.082959  0.143766  0.017497   \n",
       "3  0.135074  0.096405  0.059797  ...  0.097248  0.079721  0.189882  0.030258   \n",
       "4  0.664374  0.036919  0.331721  ...  0.188886  0.175489  0.172606  0.058966   \n",
       "\n",
       "         73        74        75        76        77        78  \n",
       "0  0.016335  0.118973  0.129160  0.072585  0.100532  0.147335  \n",
       "1  0.042575  0.174255  0.159475  0.112408  0.367571  0.253594  \n",
       "2  0.029017  0.096281  0.042791  0.049105  0.397772  0.136151  \n",
       "3  0.076895  0.081524  0.069514  0.099842  0.183957  0.230961  \n",
       "4  0.065165  0.099678  0.077754  0.125112  0.175304  0.111650  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crop_presence_data = pd.read_csv(\"./Data/Crop_Location_Data_20221201.csv\")\n",
    "display(crop_presence_data.head())\n",
    "vv_data = data_preprocess(pd.read_csv(\"./Data/S1DataVV.csv\",index_col=0))\n",
    "vh_data = data_preprocess(pd.read_csv(\"./Data/S1DataVH.csv\",index_col=0))\n",
    "display(vh_data.head())\n",
    "display(vv_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a191cd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600\n"
     ]
    }
   ],
   "source": [
    "# Combine VV & VH Data such [ loc1[ date1[VV,VH],date2[VV,VH],...],loc2[ date1[VV,VH],date2[VV,VH],...],...]\n",
    "vv_x=vv_data.apply(lambda x: [i for i in x.values],axis=1).tolist()\n",
    "vh_y=vh_data.apply(lambda x: [i for i in x.values],axis=1).tolist()\n",
    "print(len(vv_x),len(vh_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a86bc676",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([vv_x,vh_y])\n",
    "x=x.transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99683b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =crop_presence_data.copy()\n",
    "target_value=data['Class of Land'].apply(lambda x: 1 if x=='Rice' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cba41097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250\n"
     ]
    }
   ],
   "source": [
    "# Loading Test Data\n",
    "os.makedirs('./Submission_Data',exist_ok=True)\n",
    "submit_fp ='./Submission_Data/'\n",
    "submission_df = pd.read_csv('./Data/challenge_1_submission_template_correct_columns_fixed.csv')\n",
    "\n",
    "replace_data,test_vv_fp,test_vh_fp = False,\"./Data/TestS1DataVVProcessed.csv\",\"./Data/TestS1DataVHProcessed.csv\"\n",
    "if not os.path.exists(test_vv_fp) or replace_data:\n",
    "    # extract data\n",
    "    pass\n",
    "test_vv = pd.read_csv(test_vv_fp)\n",
    "test_vh = pd.read_csv(test_vh_fp)\n",
    "vv_x=test_vv.apply(lambda x: [i for i in x.values],axis=1).tolist()\n",
    "vh_y=test_vh.apply(lambda x: [i for i in x.values],axis=1).tolist()\n",
    "print(len(vv_x),len(vh_y))\n",
    "X_test=np.array([vv_x,vh_y])\n",
    "X_test=X_test.transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55a0b4",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20590df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow check cuda availability\n",
    "devices_=tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_logical_device_configuration(device=devices_[0],logical_devices=[tf.config.LogicalDeviceConfiguration(memory_limit=1024*22)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b208670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequenial Keras model 2 LSTM Layer with 10 neurons each and 1 Dense layer with 1 neuron\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=(79,2)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(30,return_sequences=True)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(30)))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.RMSprop(0.001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a2ec230",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "EPOCHS=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3db04444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test using sklearn random split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, target_value, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert the data into numpy array and reshape the data to fit the model\n",
    "X_train = X_train.reshape(-1,79,2)\n",
    "X_val = X_val.reshape(-1,79,2)\n",
    "y_train = y_train.to_numpy().reshape(-1,1)\n",
    "y_val = y_val.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad15c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 5s 105ms/step - loss: 0.6696 - accuracy: 0.4771 - val_loss: 0.5809 - val_accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.4763 - accuracy: 0.8125 - val_loss: 0.5117 - val_accuracy: 0.7667\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.3753 - accuracy: 0.7958 - val_loss: 0.3565 - val_accuracy: 0.7750\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.2523 - accuracy: 0.9062 - val_loss: 0.2168 - val_accuracy: 0.9333\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.2435 - accuracy: 0.9271 - val_loss: 0.2460 - val_accuracy: 0.9417\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1837 - accuracy: 0.9542 - val_loss: 0.4227 - val_accuracy: 0.8583\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1717 - accuracy: 0.9458 - val_loss: 0.2240 - val_accuracy: 0.9333\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1417 - accuracy: 0.9563 - val_loss: 0.2418 - val_accuracy: 0.9333\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.1673 - accuracy: 0.9438 - val_loss: 0.1767 - val_accuracy: 0.9500\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.1685 - accuracy: 0.9438 - val_loss: 0.1560 - val_accuracy: 0.9667\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1262 - accuracy: 0.9646 - val_loss: 0.1708 - val_accuracy: 0.9583\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.1553 - accuracy: 0.9500 - val_loss: 0.1114 - val_accuracy: 0.9750\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1238 - accuracy: 0.9625 - val_loss: 0.1202 - val_accuracy: 0.9750\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1364 - accuracy: 0.9583 - val_loss: 0.1266 - val_accuracy: 0.9750\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1151 - accuracy: 0.9563 - val_loss: 0.1152 - val_accuracy: 0.9750\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1062 - accuracy: 0.9708 - val_loss: 0.1055 - val_accuracy: 0.9750\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.1227 - accuracy: 0.9646 - val_loss: 0.0863 - val_accuracy: 0.9833\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1293 - accuracy: 0.9625 - val_loss: 0.1277 - val_accuracy: 0.9667\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1051 - accuracy: 0.9646 - val_loss: 0.1268 - val_accuracy: 0.9750\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0876 - accuracy: 0.9750 - val_loss: 0.0741 - val_accuracy: 0.9833\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1160 - accuracy: 0.9667 - val_loss: 0.1185 - val_accuracy: 0.9583\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1214 - accuracy: 0.9583 - val_loss: 0.0998 - val_accuracy: 0.9667\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1203 - accuracy: 0.9646 - val_loss: 0.0764 - val_accuracy: 0.9833\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1036 - accuracy: 0.9708 - val_loss: 0.0773 - val_accuracy: 0.9833\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0950 - accuracy: 0.9729 - val_loss: 0.0890 - val_accuracy: 0.9667\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0893 - accuracy: 0.9771 - val_loss: 0.0887 - val_accuracy: 0.9750\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1113 - accuracy: 0.9667 - val_loss: 0.0768 - val_accuracy: 0.9833\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1003 - accuracy: 0.9667 - val_loss: 0.0923 - val_accuracy: 0.9833\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0999 - accuracy: 0.9646 - val_loss: 0.1410 - val_accuracy: 0.9750\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0901 - accuracy: 0.9688 - val_loss: 0.0858 - val_accuracy: 0.9750\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0967 - accuracy: 0.9729 - val_loss: 0.0742 - val_accuracy: 0.9833\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0989 - accuracy: 0.9729 - val_loss: 0.0744 - val_accuracy: 0.9833\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0892 - accuracy: 0.9771 - val_loss: 0.0885 - val_accuracy: 0.9750\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0958 - accuracy: 0.9708 - val_loss: 0.0795 - val_accuracy: 0.9833\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0811 - accuracy: 0.9771 - val_loss: 0.1092 - val_accuracy: 0.9750\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0954 - accuracy: 0.9729 - val_loss: 0.1501 - val_accuracy: 0.9583\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0783 - accuracy: 0.9771 - val_loss: 0.0705 - val_accuracy: 0.9917\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0921 - accuracy: 0.9750 - val_loss: 0.1062 - val_accuracy: 0.9667\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0823 - accuracy: 0.9729 - val_loss: 0.0671 - val_accuracy: 0.9833\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0820 - accuracy: 0.9812 - val_loss: 0.0628 - val_accuracy: 0.9833\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0791 - accuracy: 0.9771 - val_loss: 0.0753 - val_accuracy: 0.9833\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0697 - accuracy: 0.9771 - val_loss: 0.0763 - val_accuracy: 0.9667\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0584 - accuracy: 0.9854 - val_loss: 0.0960 - val_accuracy: 0.9750\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0903 - accuracy: 0.9729 - val_loss: 0.0602 - val_accuracy: 0.9833\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1182 - accuracy: 0.9667 - val_loss: 0.1095 - val_accuracy: 0.9750\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0698 - accuracy: 0.9812 - val_loss: 0.0894 - val_accuracy: 0.9750\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0697 - accuracy: 0.9792 - val_loss: 0.0821 - val_accuracy: 0.9667\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0904 - accuracy: 0.9708 - val_loss: 0.0568 - val_accuracy: 0.9917\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0716 - accuracy: 0.9833 - val_loss: 0.1042 - val_accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0555 - accuracy: 0.9896 - val_loss: 0.0481 - val_accuracy: 0.9917\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0673 - accuracy: 0.9812 - val_loss: 0.0506 - val_accuracy: 0.9917\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0821 - accuracy: 0.9771 - val_loss: 0.1115 - val_accuracy: 0.9667\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0634 - accuracy: 0.9833 - val_loss: 0.0621 - val_accuracy: 0.9750\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0661 - accuracy: 0.9792 - val_loss: 0.0903 - val_accuracy: 0.9750\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 0.0596 - val_accuracy: 0.9750\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0570 - accuracy: 0.9854 - val_loss: 0.0603 - val_accuracy: 0.9833\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0572 - accuracy: 0.9833 - val_loss: 0.0896 - val_accuracy: 0.9833\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0637 - accuracy: 0.9792 - val_loss: 0.0695 - val_accuracy: 0.9667\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0713 - accuracy: 0.9750 - val_loss: 0.0466 - val_accuracy: 0.9917\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0845 - accuracy: 0.9750 - val_loss: 0.0769 - val_accuracy: 0.9833\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0526 - accuracy: 0.9792 - val_loss: 0.0519 - val_accuracy: 0.9917\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 0.0475 - val_accuracy: 0.9917\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0533 - accuracy: 0.9812 - val_loss: 0.0899 - val_accuracy: 0.9750\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0565 - accuracy: 0.9812 - val_loss: 0.0439 - val_accuracy: 0.9917\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0597 - accuracy: 0.9750 - val_loss: 0.0954 - val_accuracy: 0.9667\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0423 - accuracy: 0.9854 - val_loss: 0.0476 - val_accuracy: 0.9917\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 0.0886 - val_accuracy: 0.9833\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0527 - accuracy: 0.9833 - val_loss: 0.0383 - val_accuracy: 0.9917\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0427 - accuracy: 0.9896 - val_loss: 0.0467 - val_accuracy: 0.9917\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0474 - accuracy: 0.9812 - val_loss: 0.0431 - val_accuracy: 0.9917\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0445 - accuracy: 0.9875 - val_loss: 0.1296 - val_accuracy: 0.9250\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0443 - accuracy: 0.9833 - val_loss: 0.0230 - val_accuracy: 0.9917\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0824 - accuracy: 0.9771 - val_loss: 0.0489 - val_accuracy: 0.9917\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0434 - accuracy: 0.9792 - val_loss: 0.0442 - val_accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0404 - accuracy: 0.9833 - val_loss: 0.0358 - val_accuracy: 0.9917\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0396 - accuracy: 0.9896 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 0.0386 - val_accuracy: 0.9917\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0655 - accuracy: 0.9771 - val_loss: 0.0293 - val_accuracy: 0.9917\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0380 - accuracy: 0.9812 - val_loss: 0.0416 - val_accuracy: 0.9833\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0275 - val_accuracy: 0.9917\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0278 - accuracy: 0.9875 - val_loss: 0.0200 - val_accuracy: 0.9917\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0524 - accuracy: 0.9812 - val_loss: 0.0411 - val_accuracy: 0.9833\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0176 - val_accuracy: 0.9917\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0165 - accuracy: 0.9937 - val_loss: 0.0454 - val_accuracy: 0.9833\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0206 - accuracy: 0.9917 - val_loss: 0.0686 - val_accuracy: 0.9833\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0341 - accuracy: 0.9875 - val_loss: 0.1356 - val_accuracy: 0.9333\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0538 - accuracy: 0.9854 - val_loss: 0.0668 - val_accuracy: 0.9833\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.0110 - val_accuracy: 0.9917\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0353 - accuracy: 0.9833 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0257 - accuracy: 0.9937 - val_loss: 0.0365 - val_accuracy: 0.9833\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0242 - accuracy: 0.9896 - val_loss: 0.0762 - val_accuracy: 0.9833\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0279 - accuracy: 0.9896 - val_loss: 0.0168 - val_accuracy: 0.9917\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.0189 - val_accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0376 - accuracy: 0.9896 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 0.0164 - val_accuracy: 0.9917\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0174 - val_accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9917\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0239 - accuracy: 0.9937 - val_loss: 0.0208 - val_accuracy: 0.9917\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0253 - accuracy: 0.9896 - val_loss: 0.0139 - val_accuracy: 0.9917\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02032529190182686, 1.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model with model checkpoint best validation loss and early stopping with patience 5\n",
    "checkpoint_filepath = './checkpoint/'\n",
    "os.makedirs(os.path.dirname(checkpoint_filepath), exist_ok=True)\n",
    "checkpoint_filepath = './checkpoint/checkpoint2'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, validation_data=(X_val, y_val), callbacks=[model_checkpoint_callback,early_stopping])\n",
    "model.fit(np.concatenate([X_train,X_val],axis=0), np.concatenate([y_train,y_val],axis=0), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,validation_split=0.2, callbacks=[model_checkpoint_callback])\n",
    "model.load_weights(checkpoint_filepath)\n",
    "model.evaluate(x=X_val,y=y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26e1891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('./checkpoint/Bilstm_best1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a9afa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02032529190182686, 1.0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_val,y=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e42928bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "submission_df['target']=model.predict(X_test).argmax(axis=1)\n",
    "submission_df['target']=submission_df['target'].apply(lambda x: 'Rice' if x==1 else 'Non Rice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91ada140",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df=pd.read_csv('./Submission_Data/Best_Out_VV_VH_Bidirectional_LSTM98.csv').rename({'target':'best_target'},axis=1).merge(submission_df,on=['id'],how='left')\n",
    "compare_df['is_equal']=compare_df.apply(lambda x: 1 if x['best_target']==x['target'] else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2df9ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(os.path.join(submit_fp,\"Out_VV_VH_Bidirectional_LSTM.csv\"),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63823ece",
   "metadata": {},
   "source": [
    "### Experiment 3: RVI Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7249e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data Set\n",
    "\n",
    "def data_preprocess(df_input):\n",
    "    df = df_input.copy()\n",
    "    miss_rate=df.apply(lambda x: 1-x.isna().value_counts()[False]/len(x),axis=0)\n",
    "    df.drop(miss_rate[miss_rate>0.1].index,axis=1,inplace=True)\n",
    "    df.replace([-32768.000000],np.nan,inplace=True)\n",
    "    df.fillna(df.mean(axis=0),inplace=True)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a326bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude and Longitude Class of Land\n",
       "0   (10.323727047081501, 105.2516346045924)          Rice\n",
       "1  (10.322364360592521, 105.27843410554115)          Rice\n",
       "2  (10.321455902933202, 105.25254306225168)          Rice\n",
       "3  (10.324181275911162, 105.25118037576274)          Rice\n",
       "4  (10.324635504740822, 105.27389181724476)          Rice"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.268812</td>\n",
       "      <td>1.177804</td>\n",
       "      <td>1.078746</td>\n",
       "      <td>0.885944</td>\n",
       "      <td>1.011423</td>\n",
       "      <td>0.576550</td>\n",
       "      <td>0.825536</td>\n",
       "      <td>1.215215</td>\n",
       "      <td>0.617741</td>\n",
       "      <td>0.730946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805856</td>\n",
       "      <td>0.945279</td>\n",
       "      <td>0.683113</td>\n",
       "      <td>0.651854</td>\n",
       "      <td>0.615287</td>\n",
       "      <td>0.616962</td>\n",
       "      <td>0.599794</td>\n",
       "      <td>0.790055</td>\n",
       "      <td>0.555535</td>\n",
       "      <td>0.205384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.386990</td>\n",
       "      <td>0.986378</td>\n",
       "      <td>1.056098</td>\n",
       "      <td>1.269690</td>\n",
       "      <td>1.002210</td>\n",
       "      <td>0.828510</td>\n",
       "      <td>0.486269</td>\n",
       "      <td>0.791543</td>\n",
       "      <td>0.898176</td>\n",
       "      <td>0.586530</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029705</td>\n",
       "      <td>0.799573</td>\n",
       "      <td>1.248745</td>\n",
       "      <td>0.693501</td>\n",
       "      <td>0.635611</td>\n",
       "      <td>0.494811</td>\n",
       "      <td>0.697652</td>\n",
       "      <td>0.331825</td>\n",
       "      <td>0.200730</td>\n",
       "      <td>0.691492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.853811</td>\n",
       "      <td>1.424612</td>\n",
       "      <td>0.946962</td>\n",
       "      <td>0.856900</td>\n",
       "      <td>0.654258</td>\n",
       "      <td>0.842964</td>\n",
       "      <td>0.734223</td>\n",
       "      <td>1.134528</td>\n",
       "      <td>0.625878</td>\n",
       "      <td>0.831439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751218</td>\n",
       "      <td>0.947396</td>\n",
       "      <td>0.798228</td>\n",
       "      <td>0.825979</td>\n",
       "      <td>0.471235</td>\n",
       "      <td>0.610515</td>\n",
       "      <td>0.566653</td>\n",
       "      <td>0.367716</td>\n",
       "      <td>0.291665</td>\n",
       "      <td>0.230669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.026404</td>\n",
       "      <td>1.012573</td>\n",
       "      <td>0.563292</td>\n",
       "      <td>0.870734</td>\n",
       "      <td>0.808345</td>\n",
       "      <td>0.884417</td>\n",
       "      <td>0.567212</td>\n",
       "      <td>0.828071</td>\n",
       "      <td>0.510699</td>\n",
       "      <td>0.883200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822316</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.953764</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.669149</td>\n",
       "      <td>0.490925</td>\n",
       "      <td>0.780768</td>\n",
       "      <td>0.498302</td>\n",
       "      <td>0.428138</td>\n",
       "      <td>0.259073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.117442</td>\n",
       "      <td>0.664129</td>\n",
       "      <td>0.556181</td>\n",
       "      <td>0.800441</td>\n",
       "      <td>0.853133</td>\n",
       "      <td>0.769346</td>\n",
       "      <td>0.603781</td>\n",
       "      <td>0.777530</td>\n",
       "      <td>0.610921</td>\n",
       "      <td>1.151756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585791</td>\n",
       "      <td>0.458077</td>\n",
       "      <td>0.514433</td>\n",
       "      <td>0.490509</td>\n",
       "      <td>0.476429</td>\n",
       "      <td>0.522104</td>\n",
       "      <td>0.290942</td>\n",
       "      <td>0.519854</td>\n",
       "      <td>0.452367</td>\n",
       "      <td>0.200230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.268812  1.177804  1.078746  0.885944  1.011423  0.576550  0.825536   \n",
       "1  1.386990  0.986378  1.056098  1.269690  1.002210  0.828510  0.486269   \n",
       "2  0.853811  1.424612  0.946962  0.856900  0.654258  0.842964  0.734223   \n",
       "3  1.026404  1.012573  0.563292  0.870734  0.808345  0.884417  0.567212   \n",
       "4  1.117442  0.664129  0.556181  0.800441  0.853133  0.769346  0.603781   \n",
       "\n",
       "          7         8         9  ...        75        76        77        78  \\\n",
       "0  1.215215  0.617741  0.730946  ...  0.805856  0.945279  0.683113  0.651854   \n",
       "1  0.791543  0.898176  0.586530  ...  1.029705  0.799573  1.248745  0.693501   \n",
       "2  1.134528  0.625878  0.831439  ...  0.751218  0.947396  0.798228  0.825979   \n",
       "3  0.828071  0.510699  0.883200  ...  0.822316  0.957821  0.953764  0.751689   \n",
       "4  0.777530  0.610921  1.151756  ...  0.585791  0.458077  0.514433  0.490509   \n",
       "\n",
       "         79        80        81        82        83        84  \n",
       "0  0.615287  0.616962  0.599794  0.790055  0.555535  0.205384  \n",
       "1  0.635611  0.494811  0.697652  0.331825  0.200730  0.691492  \n",
       "2  0.471235  0.610515  0.566653  0.367716  0.291665  0.230669  \n",
       "3  0.669149  0.490925  0.780768  0.498302  0.428138  0.259073  \n",
       "4  0.476429  0.522104  0.290942  0.519854  0.452367  0.200230  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crop_presence_data = pd.read_csv(\"./Data/Crop_Location_Data_20221201.csv\")\n",
    "display(crop_presence_data.head())\n",
    "rvi_data = data_preprocess(pd.read_csv(\"./Data/Raw RVI values.csv\"))\n",
    "display(rvi_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2b632b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "# Combine VV & VH Data such [ loc1[ date1[VV,VH],date2[VV,VH],...],loc2[ date1[VV,VH],date2[VV,VH],...],...]\n",
    "rvi_x=rvi_data.apply(lambda x: [i for i in x.values],axis=1).tolist()\n",
    "print(len(rvi_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a828caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([rvi_x]).reshape(-1,len(rvi_x[0]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87adc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =crop_presence_data.copy()\n",
    "target_value=data['Class of Land'].apply(lambda x: 1 if x=='Rice' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38409862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "# Loading Test Data\n",
    "os.makedirs('./Submission_Data',exist_ok=True)\n",
    "submit_fp ='./Submission_Data/'\n",
    "submission_df = pd.read_csv('./Data/challenge_1_submission_template_correct_columns_fixed.csv')\n",
    "\n",
    "replace_data,test_vv_fp = False,\"./Data/Raw RVI test values.csv\",\n",
    "if not os.path.exists(test_vv_fp) or replace_data:\n",
    "    # extract data\n",
    "    pass\n",
    "test_vv = pd.read_csv(test_vv_fp)\n",
    "rvi_x=test_vv.apply(lambda x: [i for i in x.values],axis=1).tolist()\n",
    "print(len(rvi_x))\n",
    "X_test=np.array(rvi_x).reshape(-1,len(rvi_x[0]),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07343f8b",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d83838e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow check cuda availability\n",
    "devices_=tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_logical_device_configuration(device=devices_[0],logical_devices=[tf.config.LogicalDeviceConfiguration(memory_limit=1024*22)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe0194a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 85, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0b783e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequenial Keras model 2 LSTM Layer with 10 neurons each and 1 Dense layer with 1 neuron\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=(x.shape[1],1)))\n",
    "model.add(layers.LSTM(10,return_sequences=True))\n",
    "model.add(layers.LSTM(10))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd88e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "EPOCHS=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff67de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test using sklearn random split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, target_value, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert the data into numpy array and reshape the data to fit the model\n",
    "y_train = y_train.to_numpy().reshape(-1,1)\n",
    "y_val = y_val.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe1eaac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 3s 76ms/step - loss: 0.7034 - accuracy: 0.4292 - val_loss: 0.6973 - val_accuracy: 0.4750\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.6936 - accuracy: 0.5063 - val_loss: 0.6935 - val_accuracy: 0.4750\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.6883 - accuracy: 0.5063 - val_loss: 0.6903 - val_accuracy: 0.4750\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.6834 - accuracy: 0.5063 - val_loss: 0.6843 - val_accuracy: 0.4750\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.6763 - accuracy: 0.5833 - val_loss: 0.6749 - val_accuracy: 0.6083\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.6670 - accuracy: 0.5562 - val_loss: 0.6685 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.6556 - accuracy: 0.6542 - val_loss: 0.6504 - val_accuracy: 0.7083\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.6319 - accuracy: 0.7188 - val_loss: 0.6279 - val_accuracy: 0.6833\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5911 - accuracy: 0.7979 - val_loss: 0.5661 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4946 - accuracy: 0.9271 - val_loss: 0.4109 - val_accuracy: 0.9500\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2995 - accuracy: 0.9583 - val_loss: 0.2163 - val_accuracy: 0.9667\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1681 - accuracy: 0.9708 - val_loss: 0.1478 - val_accuracy: 0.9750\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1054 - accuracy: 0.9812 - val_loss: 0.0878 - val_accuracy: 0.9917\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0679 - accuracy: 0.9896 - val_loss: 0.0604 - val_accuracy: 0.9917\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0373 - accuracy: 0.9958 - val_loss: 0.0631 - val_accuracy: 0.9833\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9750\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0251 - accuracy: 0.9958 - val_loss: 0.1278 - val_accuracy: 0.9667\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0483 - accuracy: 0.9875 - val_loss: 0.1138 - val_accuracy: 0.9583\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0385 - accuracy: 0.9917 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0198 - accuracy: 0.9979 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 0.1243 - val_accuracy: 0.9667\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0454 - accuracy: 0.9854 - val_loss: 0.0457 - val_accuracy: 0.9833\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.0310 - val_accuracy: 0.9917\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9917\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0154 - accuracy: 0.9937 - val_loss: 0.0164 - val_accuracy: 0.9917\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 9.8780e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 9.6396e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 9.4044e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 9.1774e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 8.9661e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 8.7565e-04 - accuracy: 1.0000 - val_loss: 9.8893e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 8.5563e-04 - accuracy: 1.0000 - val_loss: 9.5260e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 8.3617e-04 - accuracy: 1.0000 - val_loss: 9.1425e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 8.1677e-04 - accuracy: 1.0000 - val_loss: 8.9854e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 7.9819e-04 - accuracy: 1.0000 - val_loss: 8.8760e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 7.8245e-04 - accuracy: 1.0000 - val_loss: 8.7121e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 7.6424e-04 - accuracy: 1.0000 - val_loss: 8.3815e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 7.4760e-04 - accuracy: 1.0000 - val_loss: 8.1474e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 7.3263e-04 - accuracy: 1.0000 - val_loss: 7.8818e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 7.1630e-04 - accuracy: 1.0000 - val_loss: 7.8352e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 7.0125e-04 - accuracy: 1.0000 - val_loss: 7.5667e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 6.8634e-04 - accuracy: 1.0000 - val_loss: 7.4096e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 6.7238e-04 - accuracy: 1.0000 - val_loss: 7.2378e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 6.5899e-04 - accuracy: 1.0000 - val_loss: 7.0726e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 6.4547e-04 - accuracy: 1.0000 - val_loss: 6.9045e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 6.3264e-04 - accuracy: 1.0000 - val_loss: 6.7640e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 6.2008e-04 - accuracy: 1.0000 - val_loss: 6.6330e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 6.0790e-04 - accuracy: 1.0000 - val_loss: 6.5031e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 5.9605e-04 - accuracy: 1.0000 - val_loss: 6.3698e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 5.8460e-04 - accuracy: 1.0000 - val_loss: 6.2202e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 5.7359e-04 - accuracy: 1.0000 - val_loss: 6.0890e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7dc5dcdc0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model with model checkpoint best validation loss and early stopping with patience 5\n",
    "checkpoint_filepath = './checkpoint/'\n",
    "os.makedirs(os.path.dirname(checkpoint_filepath), exist_ok=True)\n",
    "checkpoint_filepath = './checkpoint/checkpoint2'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, validation_data=(X_val, y_val), callbacks=[model_checkpoint_callback,early_stopping])\n",
    "model.fit(np.concatenate([X_train,X_val],axis=0), np.concatenate([y_train,y_val],axis=0), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,validation_split=0.2, callbacks=[model_checkpoint_callback,early_stopping])\n",
    "# model.load_weights(checkpoint_filepath)\n",
    "# model.evaluate(x=X_val,y=y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f86366d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0339e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006033917306922376, 1.0]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_val,y=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "780b7754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "submission_df['target']=model.predict(X_test).argmax(axis=1)\n",
    "submission_df['target']=submission_df['target'].apply(lambda x: 'Rice' if x==1 else 'Non Rice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb10fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df=pd.read_csv('./Data/Best_submission.csv').rename({'target':'best_target'},axis=1).merge(submission_df,on=['id'],how='left')\n",
    "compare_df['is_equal']=compare_df.apply(lambda x: 1 if x['best_target']==x['target'] else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7c33493",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(os.path.join(submit_fp,\"Out_RVI.csv\"),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d63ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ey_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
